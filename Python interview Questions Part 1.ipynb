{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b017c94-1379-427c-bbff-806d8160d1c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Python Interview Questions for Data Engineers – Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad27f649-d2d6-4a3f-a479-58b9a689f3bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Python Interview Questions for Data Engineers – Part 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95163004-dfe7-48c3-ad30-af38a773f4cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Large File Ingestion – Generators vs Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d26570a4-407b-4daf-ba09-3d089a74b4ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Interview Question (Context + Question Together)**\n",
    "\n",
    "You are ingesting a 50GB application log file in Python and you only need to filter **ERROR** records before loading them into the Bronze layer.\n",
    "If you read the entire file into a list, the job crashes due to memory issues.\n",
    "How would you solve this in Python and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe2831ac-5625-4ff1-8b9b-d6bb74f40ed6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_logs(path):\n",
    "    with open(path,'r') as f:\n",
    "        for line in f:\n",
    "            yield line\n",
    "\n",
    "error_logs=(log for log in read_logs(\"app.log\") if \"ERROR\" in log)\n",
    "\n",
    "for log in error_logs:\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d637be1c-27ab-4b6b-aa3f-126a943a1348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Schema Builder Bug – Mutable Default Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01ee2326-3db2-469b-9e9e-88bf50f1df6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Interview Question**\n",
    "\n",
    "You are writing a reusable Python function to dynamically build a list of columns for transformation.\n",
    "This function is called multiple times in the same pipeline run.\n",
    "However, columns from previous runs keep appearing unexpectedly.\n",
    "What is wrong in this code and how do you fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69a8c92d-2228-4e4a-be4b-20bc7cef6d9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#BUG CODE\n",
    "def add_column(col, cols=[]):\n",
    "    cols.append(col)\n",
    "    return cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48b97d29-f2b2-48dd-8890-b85a2d114dee",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "BUG CODE output Function call"
    }
   },
   "outputs": [],
   "source": [
    "add_column(\"order_id\")\n",
    "print(add_column(\"customer_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ddc731d-83b0-4a2c-85a0-1889677887d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_column(col, cols=[]):\n",
    "    if cols is None:\n",
    "        cols=[]\n",
    "    cols.append(col)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e384d6ed-2485-4cb4-a62d-319cac3d3762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "add_column(\"order_id\")\n",
    "print(add_column(\"customer_id\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05717a42-2c9e-485f-b82e-8ceb380fe4b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Bronze to Silver Transformation – Shallow Copy Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1c87ece-c6a0-4ce0-8b80-172db0dbde63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Interview Question**\n",
    "\n",
    "You load records into the Bronze layer, copy them, and enrich them for the Silver layer.\n",
    "After transformation, you notice Bronze data has also changed.\n",
    "Here is the code. Why is this happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af825420-239a-462e-a293-20ff92c28b0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "records = [{\"id\": 1, \"tags\": [\"new\"]}]\n",
    "silver = records.copy()\n",
    "silver[0][\"tags\"].append(\"processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66576f38-7acd-4c8a-816c-3757d2d9d316",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0522b2ed-4dfb-4b76-8f36-4cfab627062d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "records = [{\"id\": 1, \"tags\": [\"new\"]}]\n",
    "silver=copy.deepcopy(records)\n",
    "silver[0][\"tags\"].append(\"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8568eddf-bc6f-4227-bb34-765ccf8c13ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41995437-a0bd-41e1-a20e-6eb837bee42a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7396146b-d54f-4f40-8533-3a7be0cd6d99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Generic Pipeline Execution – *args & **kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aac2f128-6539-4df5-9491-e11a8ff316e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Interview Question**\n",
    "\n",
    "You are building a Python pipeline framework where different transformation steps receive different parameters.\n",
    "How do you design a generic executor that supports flexible inputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41102682-dd9f-4f48-8a4d-9d01fa6f23d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Answer Explanation**\n",
    "\n",
    "*args and **kwargs allow us to pass variable parameters dynamically, making pipelines configurable and reusable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6443769c-f171-48c8-8483-d678ef6265dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_step(step, *args, **kwargs):\n",
    "    return step(*args, **kwargs)\n",
    "\n",
    "def transform(value, multiplier=2):\n",
    "    return value * multiplier\n",
    "\n",
    "run_step(transform, 10, multiplier=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d1c5568-39e7-4267-b9ca-16f8cdab424a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5. Retry Failure – Idempotent ETL Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0f35d36-bb5e-4a1e-919d-75ac585c1363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Interview Question**\n",
    "\n",
    "your Airflow task fails after writing partial data and then retries.\n",
    "How do you design your Python ETL so that retries don’t create duplicate records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a509c9ef-9be4-4577-9465-21c254de41e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def write_data(path, rows):\n",
    "    tmp = Path(path + \".tmp\")\n",
    "    final = Path(path)\n",
    "\n",
    "    with open(tmp, \"w\") as f:\n",
    "        for r in rows:\n",
    "            f.write(str(r) + \"\\n\")\n",
    "\n",
    "    tmp.replace(final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "532f5f6c-d776-4125-832d-fc5b63e79b4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "6. Date Partition Bug – Timezone Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91908220-79ce-4331-a0ba-4be2361fbbca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Interview Question**\n",
    "\n",
    "Your pipeline partitions data by date, but records appear in the wrong partition depending on server timezone.\n",
    "How do you fix this in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd050072-38c6-40a2-87f6-b8698dee8e49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime,timezone\n",
    "\n",
    "datetime.now(timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e21f60f-1afd-4dfe-ac40-15cc95eedad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Python interview Questions Part 1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
